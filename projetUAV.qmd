---
title: "Optimisation de la trajectoire d'un drone "
subtitle: "MTH8408"
author:
  - name: Jouglet Nicolas, Dawut Esse, Joey Van Melle
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:

    keep-tex: false
    documentclass: article
    include-in-header:
      - text: |
            \usepackage{eulervm}
            \usepackage{xspace}
            \usepackage[francais]{babel}
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
    fig-format: png
engine: julia
---


Le contrôle de drones quadrotors est un enjeu majeur dans le domaine de la robotique autonome en raison de leur grande maniabilité, mais aussi de leur instabilité naturelle.  
Ce projet vise à concevoir un **contrôleur optimal** capable de suivre une trajectoire prédéfinie tout en minimisant la consommation d'énergie.  
Nous nous appuyons pour cela sur l’approche proposée par Suicmez et Kutay (2014), qui repose sur la commande optimale en temps discrèt.

# Contexte du papier

- Les **quadrotors** sont des drones à 4 moteurs capables de **décoller et atterrir verticalement (VTOL)** et d’exécuter des **manœuvres agiles**.
- Ce sont des systèmes **fortement non linéaires et instables**.
- Leur principale limitation : **une consommation énergétique élevée**.

#  Description de la problèmatique

Le papier traité modélise un **drone quadrotor** et conçoit une commande optimale permettant de minimiser une fonction objectif quadratique prenant en compte différent critères tels que la précision du suivi d'une trajectoire, la consommation d'énergie et la position finale. 

Afin d'obtenir la commande optimale, les auteurs du papier ont utilisé la méthode récursive de Riccati pour résoudre le problème d'optimisation quadratique en temps discret. 

Cependant d'autres méthodes peuvent être utilisées pour determiner la commande optimale, la méthode recursive de Riccati est-elle la plus efficace ?




# Description des objectifs et du plan d'action  

La première objectif du projet consiste à **reproduire le modèle dynamique du drone** puis d'y appliquer **l'algorithme reccursif de Riccati** afin de reproduire les résultats obtenu dans le papier.  
Ensuite, nous essaierons de résoudre le système avec **d'autres méthodes**, chaque méthode devra minimiser la fonction objectif.
Les différentes méthodes utilisées sont :   
- la résolution monolithique via IPOPT (optimisation non linéaire générique),  
- la résolution avec COSMO (optimisation quadratique conique),  
- et la résolution avec OSQP (optimisation quadratique à contraintes linéaires).  

Cette comparaison permettra de mettre en évidence les avantages et inconvénients de chaque méthode pour le suivi optimal de trajectoire d’un drone quadrotor tout en déterminant laquelle est la plus efficace pour cette fonction objectif. Nous allons aussi tester une méthode spécifique aux problèmes quadratiques présentée en cours, mais nous n'avons pas encore atteint cet objectif. Nous espéront y arriver d'ici
la phase 3.
 

#  Modélisation du système

## Modèle dynamique non linéaire

Dans un premier temps, le système est modélisé de façon dynamique à partir des équations de Newton :

- **Dynamique translationnelle** : influencée par la poussée verticale $U_1$ et les angles $\phi, \theta$ ;
- **Dynamique rotationnelle** : influencée par les couples de commande $U_2, U_3, U_4$.  
  
  
Le modèle dynamique est constitué de deux parties :

- Équation non linéaire pour le mouvement de translation :

\begin{equation}
\begin{bmatrix}
\ddot{x} \\
\ddot{y} \\
\ddot{z}
\end{bmatrix}
= 
-
\begin{bmatrix}
0 \\
0 \\
g
\end{bmatrix}
+ LEB 
\begin{bmatrix}
0 \\
0 \\
U_1/m
\end{bmatrix}
- \left(\frac{K_t}{m}\right)
\begin{bmatrix}
\dot{x} \\
\dot{y} \\
\dot{z}
\end{bmatrix}
\tag{1}
\end{equation}
  
Avec 
\begin{equation*}
LEB =
\begin{bmatrix}
\cos(\theta)\cos(\phi) & \sin(\theta)\sin(\phi)\cos(\psi) - \cos(\theta)\sin(\psi) & \cos(\theta)\sin(\phi)\cos(\psi) + \sin(\theta)\sin(\psi) \\
\cos(\theta)\sin(\phi) & \sin(\theta)\sin(\phi)\sin(\psi) + \cos(\theta)\cos(\psi) & \cos(\theta)\sin(\phi)\sin(\psi) - \sin(\theta)\cos(\psi) \\
-\sin(\theta)          & \sin(\theta)\cos(\phi)                                   & \cos(\theta)\cos(\phi)
\end{bmatrix}
\end{equation*}




- Équations non linéaires pour le mouvement de rotation :

\begin{equation}
\begin{bmatrix}
\dot{p} \\
\dot{q} \\
\dot{r}
\end{bmatrix}
=
\begin{bmatrix}
\frac{(I_y - I_z)}{I_x} q r \\
\frac{(I_z - I_x)}{I_y} p r \\
\frac{(I_x - I_y)}{I_z} p q
\end{bmatrix}
+
\begin{bmatrix}
\frac{U_2 d}{I_x} \\
\frac{U_3 d}{I_y} \\
\frac{U_4}{I_z}
\end{bmatrix}
\tag{2}
\end{equation}


\begin{equation}
\begin{bmatrix}
\dot{\phi} \\
\dot{\theta} \\
\dot{\psi}
\end{bmatrix}
=
\begin{bmatrix}
1 & \sin(\phi)\tan(\theta) & \cos(\phi)\tan(\theta) \\
0 & \cos(\phi) & -\sin(\phi) \\
0 & \sin(\phi)/\cos(\theta) & \cos(\phi)/\cos(\theta)
\end{bmatrix}
\begin{bmatrix}
p \\
q \\
r
\end{bmatrix}
\tag{3}
\end{equation}

## Modèle dynamique non linéaire simplifié
  
Si les perturbations par rapport à la condition de vol stationnaire sont faibles, on suppose que les vitesses angulaires du corps [p, q, r] et les dérivées des angles d’Euler $[\dot{\phi},\ \dot{\theta},\ \dot{\psi}]$ peuvent être considérées comme égales.  
On à alors :  

\begin{equation}
\begin{bmatrix}
p \\
q \\
r
\end{bmatrix}
=
\begin{bmatrix}
\dot{\phi} \\
\dot{\theta} \\
\dot{\psi}
\end{bmatrix}
\quad ; \quad
\begin{bmatrix}
\dot{p} \\
\dot{q} \\
\dot{r}
\end{bmatrix}
=
\begin{bmatrix}
\ddot{\phi} \\
\ddot{\theta} \\
\ddot{\psi}
\end{bmatrix}
\tag{4}
\end{equation}


En utilisant l'équation 4 dans l'équation 2, on obtient **l'équation d'Euler** : 

\begin{equation}
\begin{bmatrix}
\ddot{\phi} \\
\ddot{\theta} \\
\ddot{\psi}
\end{bmatrix}
=
\begin{bmatrix}
\frac{(I_y - I_z)}{I_x} \, \dot{\theta} \dot{\psi} \\
\frac{(I_z - I_x)}{I_y} \, \dot{\phi} \dot{\psi} \\
\frac{(I_x - I_y)}{I_z} \, \dot{\phi} \dot{\theta}
\end{bmatrix}
+
\begin{bmatrix}
\frac{U_2 d}{I_x} \\
\frac{U_3 d}{I_y} \\
\frac{U_4}{I_z}
\end{bmatrix}
\tag{5}
\end{equation}

## Linéarisation du modèle dynamique simplifié 

Pour utiliser l'algorithme LQT en temps discret, il est nécessaire de linéariser le modèle autour d'une condition d'équilibre (vol stationnaire).   

À ce point d’équilibre :
\begin{equation*}
\begin{aligned}
\phi &= \dot{\phi} = \theta = \dot{\theta} = \psi = \dot{\psi} = x = \dot{x} = y = \dot{y} = \dot{z} = 0,\\
z &= 1~\text{mètre.}
\end{aligned}
\end{equation*}


 
En linéarisant LEB grâce aux hypothèses du vol stationnaire on obtient  : 
\begin{equation*}
L_{EB}^{\text{lin}} \approx I_{3}
\end{equation*}

L'équation de translation (1) devient alors :   
\begin{equation}
\begin{bmatrix}
\ddot{x} \\
\ddot{y} \\
\ddot{z}
\end{bmatrix}
= 
-\begin{bmatrix}
0 \\
0 \\
g
\end{bmatrix}
+ I_{3} \begin{bmatrix}
0 \\
0 \\
U_1/m
\end{bmatrix}
\tag{6}
\end{equation}

De même en vol stationnaire $\dot{\psi} = \dot{\phi} = \dot{\theta} =0$, donc l'équation d'Euler peut s'écrire : 
\begin{equation}
\begin{bmatrix}
\ddot{\phi} \\
\ddot{\theta} \\
\ddot{\psi}
\end{bmatrix}
=
\begin{bmatrix}
\frac{U_2 d}{I_x} \\
\frac{U_3 d}{I_y} \\
\frac{U_4}{I_z}
\end{bmatrix}
\tag{7}
\end{equation}


Le modèle peut donc se résumer à : 
\begin{equation}
\begin{bmatrix}
\ddot{x} \\
\ddot{y} \\
\ddot{z}
\end{bmatrix}
= 
-\begin{bmatrix}
0 \\
0 \\
g
\end{bmatrix}
+ I_{3} \begin{bmatrix}
0 \\
0 \\
U_1/m
\end{bmatrix}
\quad ; \quad
\begin{bmatrix}
\ddot{\phi} \\
\ddot{\theta} \\
\ddot{\psi}
\end{bmatrix}
=
\begin{bmatrix}
\frac{U_2 d}{I_x} \\
\frac{U_3 d}{I_y} \\
\frac{U_4}{I_z}
\end{bmatrix}
\end{equation}

Afin de linéariser le modèle, on introduit X le vecteur d'état, Y le vecteur de sortie et le vecteur de commande U tels que : 
\begin{equation}
X =
\begin{bmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \\ x_6 \\
x_7 \\ x_8 \\ x_9 \\ x_{10} \\ x_{11} \\ x_{12}
\end{bmatrix}
=
\begin{bmatrix}
\phi \\ \dot{\phi} \\ \theta \\ \dot{\theta} \\ \psi \\ \dot{\psi} \\
x \\ \dot{x} \\ y \\ \dot{y} \\ z \\ \dot{z}
\end{bmatrix}
\quad ; \quad
Y =
\begin{bmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \\ x_6 \\
x_7 \\ x_8 \\ x_9 \\ x_{10} \\ x_{11} \\ x_{12}
\end{bmatrix}
\quad ; \quad
U =
\begin{bmatrix}
U_1 \\ U_2 \\ U_3 \\ U_4
\end{bmatrix}
\tag{6}
\end{equation}


Enfin grâce aux hypothèses de vol stationnaire on obtient le modèle linèaire suivant : 

\begin{equation}
\dot{X} = A X + B U \quad ; \quad Y = C X
\tag{7}
\end{equation}

Où A et B et C valent : 


\begin{equation}
A =
\left[
\begin{array}{cccccccccccc}
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & g & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
-g & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{array}
\right]
\tag{A}
\end{equation}

\begin{equation}
B =
\left[
\begin{array}{cccc}
0 & 0 & 0 & 0 \\
0 & \frac{1}{I_x} & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & \frac{1}{I_y} & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & \frac{1}{I_z} \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
\frac{1}{m} & 0 & 0 & 0
\end{array}
\right]
\tag{B}
\end{equation}

\begin{equation}
C = I_{12}
\tag{C}
\end{equation}


  


## Fonction Performance

La fonction performance est construite de la façon suivante : 

\begin{equation}
J = \frac{1}{2} \sum_{k = k_0}^{k_f - 1} \left( \| C_d X(k) - r(k) \|_Q^2 + \| U(k) \|_R^2 \right)
+ \frac{1}{2} \| C_d X(k_f) - r(k_f) \|_F^2
\tag{8}
\end{equation}

où $\|x\|_M^2 = x^\top M x$ est la norme quadratique pondérée par la matrice $M$, et $F$ est la matrice de coût terminal, souvent choisie égale à $Q$, donc $F = Q$.


La structure de la fonction $J$ correspond à un problème d'optimisation quadratique, tel qu'étudié dans le cadre du cours sur l'optimisation sans contrainte. En effet, il s'agit de minimiser une somme pondérée d'erreurs quadratiques entre la trajectoire suivie $C_d X(k)$ et la trajectoire de référence $r(k)$, ainsi que des efforts de commande $U(k)$ et la différence de position finale.  

La fonction $J$ est une fonction quadratique strictement convexe, car les matrices de pondération $Q$ et $R$ sont définies positives ($Q, R \succ 0$), ce qui garantit l'existence et l'unicité de la solution optimale.



## Méthode de Riccati

L’algorithme récursif de Riccati permet de résoudre ce problème efficacement sans avoir à inverser une grande matrice globale. Il procède par rétropropagation à partir de l’instant final $k_f$, ce qui est bien adapté aux problèmes de commande optimale sur un horizon fini.

Afin d'appliquer la méthode de Riccati, il est nécessaire de discretiser le temps. 


### Discrétisation du temps 
On discrétise l'équation 7 avec un pas de temps ts=0,01s, on obtient alors un modèle discret : 
\begin{equation}
X(k + 1) = A_d X(k) + B_d U(k) \quad ; \quad Y(k) = C_d X(k)
\tag{7}
\end{equation}

La discrétisation des équations continues $\dot{X} = AX + BU$ avec un pas de temps $T_s$ selon la méthode d’Euler (ordre 1) donne les équations discrètes suivantes :

\begin{equation}
A_d = I + T_s A
\quad ; \quad
B_d = T_s B
\quad ; \quad
C_d = C
\tag{8}
\end{equation}

Le terme $C_d X(k)$ correspond à la sortie du système observée. Dans notre cas, comme $C_d = I$, cela revient à comparer directement les états à la trajectoire de référence.


### Équation de Riccati
A l'aide de l'équation de Riccati on obtient l'équation permettant de trouver la solutions du problème discrétisé :

\begin{equation}
\begin{aligned}
P(k) &= A_d^T P(k+1) [I + E P(k+1)]^{-1} A_d + V \\
V &= C_d^T Q C_d \\
E &= B_d R^{-1} B_d^T \\
g(k) &= \left[ A_d^T - A_d^T P(k+1) [I + E P(k+1)]^{-1} E \right] g(k+1) + C_d^T Q r(k) \\
\bar{X}(k+1) &= [A_d - B_d L(k)] \bar{X}(k) + B_d L_g(k) g(k+1) \\
L(k) &= [R + B_d^T P(k+1) B_d]^{-1} B_d^T P(k+1) A_d \\
L_g(k) &= [R + B_d^T P(k+1) B_d]^{-1} B_d^T \\
\bar{U}(k) &= -L(k) \bar{X}(k) + L_g(k) g(k+1)
\end{aligned}
\tag{11}
\end{equation}

Avec comme conditions finales : 
\begin{equation}
\begin{aligned}
P(k_f) &= C_d^T F C_d \\
g(k_f) &= C_d^T F\, r(k_f)
\end{aligned}
\tag{13}
\end{equation}


où Q et R sont respectivement les matrices de pondération des erreurs sur les états et des efforts de commande. 

\begin{equation}
Q = \operatorname{diag}(100,\ 50,\ 10,\ 5,\ 0,\ 0,\ 100,\ 1,\ 100,\ 1,\ 1000,\ 0.1)
\quad ; \quad
R = \operatorname{diag}(10,\ 0,\ 0,\ 0)
\tag{9}
\end{equation}

De part les hypothèses faites, les angles doivent être contraints près de 0
\begin{equation}
-20^\circ < \phi < 20^\circ \quad ; \quad
-20^\circ < \theta < 20^\circ \quad ; \quad
-20^\circ < \psi < 20^\circ
\tag{10}
\end{equation} 


```{julia}
#| echo: true
#| results: hide
#| fig-show: hide
#| quiet: true
#| output: false

using Pkg
Pkg.activate("projet_env")

Pkg.add("Plots")
Pkg.add("JuMP")
Pkg.add("Ipopt")
Pkg.add("COSMO")
Pkg.add("IterativeSolvers")
Pkg.add("LinearMaps")
Pkg.add("OSQP")
Pkg.add("MathOptInterface")
Pkg.add("Dates")
Pkg.add("PrettyTables")
Pkg.add("DataFrames")


```


# Partie 2 : reproduction des résultats
  
Fonctionnement de l'algorithme :  
L'algorithme commence à la date finale $k_f$, où les conditions terminales sont imposées, puis il effectue une récursion arrière (backward) sur les matrices $P(k)$ et $g(k)$ jusqu'à l'instant initial $k_0$.  
Une fois ces matrices calculées, une simulation en avant (forward) permet d’estimer la trajectoire optimale $\bar{X}(k)$ et les commandes optimales $\bar{U}(k)$.

```{julia}

using LinearAlgebra, Plots, JuMP, Ipopt, COSMO, IterativeSolvers, LinearMaps, OSQP, MathOptInterface,Dates
start_time = now()  # début

gr()  

g = 9.81  # gravité

# Dimensions système
n = 12  # nombre d'états du drone
m = 4   # nombre d'entrées de contrôle
T = 6000  # durée de la simulation (en pas de temps)
Ts = 0.01  # pas de temps (10 ms)

# Paramètres physiques du drone
mass = 0.5 
Ix, Iy, Iz = 0.0023, 0.0023, 0.004  # moments d’inertie autour des axes 

# Matrices de coût pour le LQR
Q = Diagonal([100.0, 50.0, 10.0, 5.0, 0.0, 0.0, 100.0, 1.0, 100.0, 1.0, 1000.0, 0.1])
R = Diagonal([10.0, 1e-3, 1e-3, 1e-3])  # pondération des efforts de contrôle
F = Q  # coût terminal

# ================================
# Construction de A et B
# ================================
A = zeros(n, n)
B = zeros(n, m)

for i in 1:2:11
    A[i, i+1] = 1.0  # lien entre position et vitesse (ex: x, vx)
end


A[8, 3] = g     # acc x dépend de θ
A[10, 1] = -g   # acc y dépend de φ


B[2,2] = 1/Ix   # moment autour de x (φ̈)
B[4,3] = 1/Iy   # moment autour de y (θ̈)
B[6,4] = 1/Iz   # moment autour de z (ψ̈)
B[12,1] = 1/mass  # poussée verticale (z̈)


# ================================
# Discrétisation d’Euler
# ================================
Ad = I + Ts * A
Bd = Ts * B



# ================================
# Définition des trajectoires désirées (référence)
# ================================
r = zeros(n, T+1)

# x : montée puis descente linéaire
for k in 1:T÷2
    r[7, k] = 40.0 * (k / (T÷2))
end
for k in T÷2+1:T+1
    r[7, k] = 40.0 * (1 - (k - T÷2) / (T÷2))
end

# y : reste à 0, saute brusquement à 10 après la moitié du temps
for k in T÷2+1:T+1
    r[9, k] = 10.0
end

# z : montée douce de 1 à 20 entre 15s et 30s, puis redescente à 1m
dt = Ts
t15 = Int(15 / dt)
t30 = Int(30 / dt)

for k in 1:t15
    r[11, k] = 1.0
end
for k in t15+1:t30
    r[11, k] = 1.0 + (20.0 - 1.0) * ((k - t15) / (t30 - t15))
end
for k in t30+1:T+1
    r[11, k] = 1.0 + (20.0 - 1.0) * (1 - (k - t30) / (T + 1 - t30))
end

# ================================
# Calcul backward des gains LQR (formulation récursive de Riccati)
# ================================

# Allocation des vecteurs/matrices pour les gains
P = Vector{Matrix{Float64}}(undef, T+1)  # matrices de Riccati
G = Vector{Vector{Float64}}(undef, T+1)  # terme d’offset (trajectoire r)
L = Vector{Matrix{Float64}}(undef, T)    # gain de feedback état
Lg = Vector{Matrix{Float64}}(undef, T)   # gain associé à la référence

# Conditions terminales
C = I(n)  # matrice d'observation (identité ici)
P[T+1] = C' * Q * C
G[T+1] = C' * Q * r[:, T+1]

# Recursion backward Riccati
for k in T:-1:1
    E = Bd * inv(R) * Bd'
    V = C' * Q * C
    invIplusE = inv(I + E * P[k+1])

    P[k] = Ad' * P[k+1] * invIplusE * Ad + V
    G[k] = (Ad' - Ad' * P[k+1] * invIplusE * E) * G[k+1] + C' * Q * r[:, k]
end

# ================================
# Simulation forward du système contrôlé
# ================================

X = zeros(n, T+1)  # états
U = zeros(m, T)    # commandes

X[:,1] = zeros(n)  # état initial
X[11, 1] = 1.0     # état initial cohérent

for k in 1:T
    # Calcul des gains à l’instant k
    L[k] = inv(R + Bd' * P[k+1] * Bd) * Bd' * P[k+1] * Ad
    Lg[k] = inv(R + Bd' * P[k+1] * Bd) * Bd'

    # Calcul de la commande optimale
    U[:,k] = -L[k] * X[:,k] + Lg[k] * G[k+1]

    # Propagation de l'état
    X[:,k+1] = Ad * X[:,k] + Bd * U[:,k]

    # Contraintes physiques : angles d'attitude max (20°)
    phi_max = deg2rad(20)
    theta_max = deg2rad(20)
    psi_max = deg2rad(20)

    # contraintex des angles
    X[1,k+1] = clamp(X[1,k+1], -phi_max, phi_max)
    X[3,k+1] = clamp(X[3,k+1], -theta_max, theta_max)
    X[5,k+1] = clamp(X[5,k+1], -psi_max, psi_max)
end

# ================================
# Visualisation de la trajectoire et de l’erreur
# ================================

z = X[11, :]  # position verticale
x = X[7, :]   # position x
y = X[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]
z = X[11, :]  # position verticale
x = X[7, :]   # position x
y = X[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]

# Références
r_z = r[11, :]
r_x = r[7, :]
r_y = r[9, :]

t = Ts .* (0:T)  # temps réel en secondes

J_state1 = 0.0
J_control1 = 0.0
for k in 1:T
    e_k = X[:,k] - r[:,k]
    J_state1   += 0.5 * (e_k' * Q * e_k)
    J_control1 += 0.5 * (U[:,k]' * R * U[:,k])
end

# Coût terminal
e_final = X[:,T+1] - r[:,T+1]
J_terminal1 = 0.5 * (e_final' * F * e_final)

# Coût total
J1 = J_state1 + J_control1 + J_terminal1

end_time = now()  # fin

elapsed = end_time - start_time

println("=== Décomposition de la fonction objectif J ===")
println("Coût d'état (suivi)      : ", J_state1)
println("Coût de contrôle         : ", J_control1)
println("Coût terminal            : ", J_terminal1)
println("Valeur totale J          : ", J1)



println("Temps d'exécution total : ", elapsed)

# Création du layout 3 lignes × 2 colonnes
plt1 = plot(layout = (4, 2), size=(1000, 800))

# Trajectoire x
plot!(plt1[1], t, x, lw=2, label="x (suivie)", color=:blue)
plot!(plt1[1], t, r_x, lw=2, label="x (référence)", linestyle=:dash, color=:red)
plot!(plt1[1], title="Trajectoire en x", xlabel="Temps (s)", ylabel="x (m)", legend=:bottomright, grid=true)

# Erreur x
plot!(plt1[2], t, e_x, lw=2, label="Erreur x", color=:purple)
plot!(plt1[2], title="Erreur de suivi (x)", xlabel="Temps (s)", ylabel="Erreur (m)", legend=:topright, grid=true)

# Trajectoire y
plot!(plt1[3], t, y, lw=2, label="y (suivie)", color=:blue)
plot!(plt1[3], t, r_y, lw=2, label="y (référence)", linestyle=:dash, color=:red)
plot!(plt1[3], title="Trajectoire en y", xlabel="Temps (s)", ylabel="y (m)", legend=:bottomright, grid=true)

# Erreur y
plot!(plt1[4], t, e_y, lw=2, label="Erreur y", color=:purple)
plot!(plt1[4], title="Erreur de suivi (y)", xlabel="Temps (s)", ylabel="Erreur (m)", legend=:topright, grid=true)

# Trajectoire z
plot!(plt1[5], t, z, lw=2, label="z (suivie)", color=:blue)
plot!(plt1[5], t, r_z, lw=2, label="z (référence)", linestyle=:dash, color=:red)
plot!(plt1[5], title="Trajectoire en z", xlabel="Temps (s)", ylabel="z (m)", legend=:bottomright, grid=true)

# Erreur z
plot!(plt1[6], t, e_z, lw=2, label="Erreur z", color=:purple)
plot!(plt1[6], title="Erreur de suivi (z)", xlabel="Temps (s)", ylabel="Erreur (m)", legend=:topright, grid=true)

plot!(plt1[7], t[1:end-1], U[1,:], lw=2, label="u1", color=:blue)
plot!(plt1[7], t[1:end-1], U[2,:], lw=2, label="u2", color=:red)
plot!(plt1[7], t[1:end-1], U[3,:], lw=2, label="u3", color=:green)
plot!(plt1[7], t[1:end-1], U[4,:], lw=2, label="u4", color=:orange)
plot!(plt1[7], title="Commandes moteurs", xlabel="Temps (s)", ylabel="U", legend=:topright, grid=true)

# Affichage
display(plt1)
```


La valeur de la fonction objectif est de 2,27*10^5. On remarque sur les graphiques que la trajectoire est plutot bien respectée avec de faibles erreurs de suivis.
La fonction objectif comporte 3 parties, une partie suivie, une partie contrôle et une partie coût position finale. On constate que la partie suivi participe pour beaucoup à la fonction objectif (99,5%).


## partie 3 : résolution avec Ipopt

Le but de cette section est de comparer les résultats obtenus dans la Partie 2 avec des résultats venant de stratégies plus générique
comme par exemple IPOPT. Le modèle est construit à partir de la librairie JuMP. 


```{julia}


using LinearAlgebra, Plots, JuMP, Ipopt, COSMO, IterativeSolvers, LinearMaps, OSQP, MathOptInterface


x0 = zeros(n)
x0[11] = 1.0                    # altitude 1 m en hover

#   Modèle JuMP « all-at-once »
model = Model(Ipopt.Optimizer)
set_optimizer_attribute(model, "print_level", 0)

@variable(model, X[1:n, 0:T])           # états
@variable(model, U[1:m, 0:T-1])         # commandes

# — dynamique linéaire
for k in 0:T-1
    @constraint(model, X[:, k+1] .== Ad * X[:, k] + Bd * U[:, k])
end

# — CONTRAINTE d’état initial  (= hover)  
@constraint(model, X[:, 0] .== x0)

# — bornes (angles ±20°, poussée 0–2 mg)
deg20 = deg2rad(20.0)
@constraint(model, -deg20 .<= X[1, :] .<=  deg20)   # φ
@constraint(model, -deg20 .<= X[3, :] .<=  deg20)   # θ
@constraint(model, -deg20 .<= X[5, :] .<=  deg20)   # ψ
@constraint(model, 0       .<= U[1, :] .<= 2 * mass * g)

# — coût
@expression(model, running_cost,
    sum( (X[:, k] - r[:, k+1])' * Q * (X[:, k] - r[:, k+1]) +
         U[:, k]' * R * U[:, k]           for k in 0:T-1) )

@expression(model, terminal_cost,
    (X[:, T] - r[:, T+1])' * F * (X[:, T] - r[:, T+1]) )

@objective(model, Min, 0.5 * running_cost + 0.5 * terminal_cost)

# — point initial 
set_start_value.(X[:, 0], x0)
set_start_value.(U, 0.0)

optimize!(model)
println("Status          : ", termination_status(model))
println("Objective value : ", objective_value(model))

# ================================
# Visualisation de la trajectoire et de l’erreur
# ================================

X_val = value.(X)
U_val = value.(U)

J_state2   = 0.0
J_control2 = 0.0

for k in 1:T
    e_k = X_val[:,k] - r[:,k]
    J_state2 += 0.5 * (e_k' * Q * e_k)[1]
end

for k in 0:T-1
    J_control2 += 0.5 * (U_val[:,k]' * R * U_val[:,k])[1]
end

e_final = X_val[:,T] - r[:,T+1]
J_terminal2 = 0.5 * (e_final' * F * e_final)[1]

J2 = J_state2 + J_control2 + J_terminal2

println("\n--- Décomposition du coût : Modèle 2 ---")
println("J_state2    = ", J_state2)
println("J_control2  = ", J_control2)
println("J_terminal2 = ", J_terminal2)
println("J2 total    = ", J2)


solutionX = Array(value.(X))

z = solutionX[11, :]  # position verticale
x = solutionX[7, :]   # position x
y = solutionX[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]
z = solutionX[11, :]  # position verticale
x = solutionX[7, :]   # position x
y = solutionX[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]

# Références
r_z = r[11, :]
r_x = r[7, :]
r_y = r[9, :]

t = Ts .* (0:T)  # temps réel en secondes

# Création du layout 3 lignes × 2 colonnes
plt2 = plot(layout = (3, 2), size=(1000, 800))

# Trajectoire x
plot!(plt2[1], t, x, lw=2, label="x (suivie)", color=:blue)
plot!(plt2[1], t, r_x, lw=2, label="x (référence)", linestyle=:dash, color=:red)
plot!(plt2[1], title="Trajectoire en x", xlabel="Temps (s)", ylabel="x (m)", legend=:bottomright, grid=true)

# Erreur x
plot!(plt2[2], t, e_x, lw=2, label="Erreur x", color=:purple)
plot!(plt2[2], title="Erreur de suivi (x)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Trajectoire y
plot!(plt2[3], t, y, lw=2, label="y (suivie)", color=:blue)
plot!(plt2[3], t, r_y, lw=2, label="y (référence)", inestyle=:dash, color=:red)
plot!(plt2[3], title="Trajectoire en y", xlabel="Temps (s)", label="y (m)", legend=:bottomright, grid=true)

# Erreur y
plot!(plt2[4], t, e_y, lw=2, label="Erreur y", color=:purple)
plot!(plt2[4], title="Erreur de suivi (y)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Trajectoire z
plot!(plt2[5], t, z, lw=2, label="z (suivie)", color=:blue)
plot!(plt2[5], t, r_z, lw=2, label="z (référence)", inestyle=:dash, color=:red)
plot!(plt2[5], title="Trajectoire en z", xlabel="Temps (s)", label="z (m)", legend=:bottomright, grid=true)

# Erreur z
plot!(plt2[6], t, e_z, lw=2, label="Erreur z", color=:purple)
plot!(plt2[6], title="Erreur de suivi (z)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Affichage
display(plt2)

```

## Analyse des résultats

La méthode IPOPT converge belle et bien pour ce problème et on obtient une valeur de l'objectif de 1.230511402197558e8. Il est possible de faire mieux avec des méthodes utilisant les propriétés du problème. Deux exemples de ces méthodes seront visités dans la prochaine section. Notons que la convergence a été atteinte en 4000 itérations pour un temps de 1.63e+001 secondes. On observe sur les graphiques que la solution proposée est efficace, en ce sens que le trajet à suivre est assez bien respectés. Notons que les erreurs sont plus grandes autour des points où il y a un changement dans la dérivée. Notre approximation étant une fonction lisse, cela n'est pas étonnant. L'erreur est aussi grande au temps final, ce qui peut être un problème dépendament des applications. Un grand déplacement programmé comme une somme de petites trajectoires pourrait facilement accumuler des erreurs. 

Notons toutefois qu'il semble y avoir une erreur à quelque part dans le code, en effet, il y a clairement une grosse erreur dans la trajectoire en z alors que le graphe de l'erreur semble indiquer que l'estimation est excellente. Nous pensons qu'il s'agit d'une erreur dans notre implémentation de la modélisation JUmP du problème. Cette modélisation étant utilisée pour les deux prochaines sections, nous pensons qu'elle explique certains de nos résultats dans cette section aussi.

À cause de cette erreur, nous n'approfondissons pas l'analyse des résultats pour l'instant. Le lecteur trouvera toutefois un tableau comparatif des méthodes à la fin de la section 5.




# Partie 4 : Résolution avec le solver COSMO

Le solveur COSMO implémente le **Conic operator splitting method **, qui est particulièrement adaptée pour résoudre de larges problèmes d'optimisation convexe et conique dont l'objectif est donné par une fonction quadratique. Il s'agit donc d'une méthode adaptée au problème monolithique creux. Le modèle est encore une fois construit à l'aide de la librairie JuMP.
```{julia}
using JuMP, COSMO, IterativeSolvers, LinearMaps, OSQP, MathOptInterface, Plots

model3 = Model(COSMO.Optimizer)

@variable(model3, X[1:n, 0:T])           # états
@variable(model3, U[1:m, 0:T-1])         # commandes

# — dynamique linéaire
for k in 0:T-1
    @constraint(model3, X[:, k+1] .== Ad * X[:, k] + Bd * U[:, k])
end

# — CONTRAINTE d’état initial  (= hover)  
@constraint(model3, X[:, 0] .== x0)

# — bornes (angles ±20°, poussée 0–2 mg)
deg20 = deg2rad(20.0)
@constraint(model3, -deg20 .<= X[1, :] .<=  deg20)   # φ
@constraint(model3, -deg20 .<= X[3, :] .<=  deg20)   # θ
@constraint(model3, -deg20 .<= X[5, :] .<=  deg20)   # ψ
@constraint(model3, 0       .<= U[1, :] .<= 2 * mass * g)

# — coût
@expression(model3, running_cost,
    sum( (X[:, k] - r[:, k+1])' * Q * (X[:, k] - r[:, k+1]) +
         U[:, k]' * R * U[:, k]           for k in 0:T-1) )

@expression(model3, terminal_cost,
    (X[:, T] - r[:, T+1])' * F * (X[:, T] - r[:, T+1]) )

@objective(model3, Min, 0.5 * running_cost + 0.5 * terminal_cost)

# — point initial 
set_start_value.(X[:, 0], x0)
set_start_value.(U, 0.0)

optimize!(model3)
println("Status          : ", termination_status(model3))

# ================================
# Visualisation de la trajectoire et de l’erreur
# ================================

X_val = value.(X)
U_val = value.(U)

J_state3   = 0.0
J_control3 = 0.0

# Coût d'état
for k in 1:T
    e_k = X_val[:,k] - r[:,k]
    J_state3 += 0.5 * (e_k' * Q * e_k)[1]
end

# Coût de contrôle
for k in 0:T-1
    J_control3 += 0.5 * (U_val[:,k]' * R * U_val[:,k])[1]
end

# Coût terminal
e_final = X_val[:,T] - r[:,T+1]
J_terminal3 = 0.5 * (e_final' * F * e_final)[1]

# Coût total
J3 = J_state3 + J_control3 + J_terminal3

println("\n--- Décomposition du coût ---")
println("J_state3    = ", J_state3)
println("J_control3  = ", J_control3)
println("J_terminal3 = ", J_terminal3)
println("J3 total    = ", J3)





solutionX = Array(value.(X))

z = solutionX[11, :]  # position verticale
x = solutionX[7, :]   # position x
y = solutionX[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]
z = solutionX[11, :]  # position verticale
x = solutionX[7, :]   # position x
y = solutionX[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]

# Références
r_z = r[11, :]
r_x = r[7, :]
r_y = r[9, :]

t = Ts .* (0:T)  # temps réel en secondes

# Création du layout 3 lignes × 2 colonnes
plt3 = plot(layout = (3, 2), size=(1000, 800))

# Trajectoire x
plot!(plt3[1], t, x, lw=2, label="x (suivie)", color=:blue)
plot!(plt3[1], t, r_x, lw=2, label="x (référence)", linestyle=:dash, color=:red)
plot!(plt3[1], title="Trajectoire en x", xlabel="Temps (s)", ylabel="x (m)", legend=:bottomright, grid=true)

# Erreur x
plot!(plt3[2], t, e_x, lw=2, label="Erreur x", color=:purple)
plot!(plt3[2], title="Erreur de suivi (x)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Trajectoire y
plot!(plt3[3], t, y, lw=2, label="y (suivie)", color=:blue)
plot!(plt3[3], t, r_y, lw=2, label="y (référence)", inestyle=:dash, color=:red)
plot!(plt3[3], title="Trajectoire en y", xlabel="Temps (s)", label="y (m)", legend=:bottomright, grid=true)

# Erreur y
plot!(plt3[4], t, e_y, lw=2, label="Erreur y", color=:purple)
plot!(plt3[4], title="Erreur de suivi (y)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Trajectoire z
plot!(plt3[5], t, z, lw=2, label="z (suivie)", color=:blue)
plot!(plt3[5], t, r_z, lw=2, label="z (référence)", inestyle=:dash, color=:red)
plot!(plt3[5], title="Trajectoire en z", xlabel="Temps (s)", label="z (m)", legend=:bottomright, grid=true)

# Erreur z
plot!(plt3[6], t, e_z, lw=2, label="Erreur z", color=:purple)
plot!(plt3[6], title="Erreur de suivi (z)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Affichage
display(plt3)


```

## Analyse des résultats

La méthode ne parvient pas à converger en moins de 5000 itérations. Toutefois, on constate une amélioration de la valeur de l'objectif qui est 10x plus petite que celle obtenue via Ipopt. Le temps de calcul est toutefois beaucoup plus élevé et on en déduit que cette méthode a une plus grande complexité que l'algorithme précédent. Nous estimons aussi que l'erreur dans notre modélisation JUmP est la cause de cette divergence. Il se pourrait que le problème ne soit plus convexe à cause de notre erreur. Nous étudiront cette hypothèse dans la phase 3.

Comme le nombre de variable est différent que dans le problème formulé et présenté dans l'article, il est difficile de comparer la complexité des deux algorithmes. Lorsque le temps de calcul est limité, il est toutefois préférable d'utiliser la méthode présentée dans l'article. Les graphes présentes une erreur qui est encore une fois espectable. On observe par aiileurs que la trajectoire en y est bien meilleure avec COSMO qu'avec Ipopt. Encore une fois, on observe de plus grandes erreurs là où il y a des changements dans la valeur des dérivées de la trajectoire à suivre. Bien que la valeur optimale obtenue via COSMO soit bonne, il est possible de faire mieux avec le solveur OSQP.

# Partie 5 : Résolution avec le solver OSQP

OSQP (Operator Splitting Quadratic Program) est une méthode servant a résoudre des problème quadratique à contraintes linéaires. C'est exactement les propriétés que nous souhaitons exploiter pour le problème monolithique.
 ```{julia}
using LinearAlgebra, Plots, JuMP, Ipopt, COSMO, IterativeSolvers, LinearMaps, OSQP, MathOptInterface

model2 = Model(OSQP.Optimizer)
set_optimizer_attribute(model, "print_level", 1)

@variable(model2, X[1:n, 0:T])           # états
@variable(model2, U[1:m, 0:T-1])         # commandes

# — dynamique linéaire
for k in 0:T-1
    @constraint(model2, X[:, k+1] .== Ad * X[:, k] + Bd * U[:, k])
end

# — CONTRAINTE d’état initial  (= hover)  
@constraint(model2, X[:, 0] .== x0)

# — bornes (angles ±20°, poussée 0–2 mg)
deg20 = deg2rad(20.0)
@constraint(model2, -deg20 .<= X[1, :] .<=  deg20)   # φ
@constraint(model2, -deg20 .<= X[3, :] .<=  deg20)   # θ
@constraint(model2, -deg20 .<= X[5, :] .<=  deg20)   # ψ
@constraint(model2, 0       .<= U[1, :] .<= 2 * mass * g)

# — coût
@expression(model2, running_cost,
    sum( (X[:, k] - r[:, k+1])' * Q * (X[:, k] - r[:, k+1]) +
         U[:, k]' * R * U[:, k]           for k in 0:T-1) )

@expression(model2, terminal_cost,
    (X[:, T] - r[:, T+1])' * F * (X[:, T] - r[:, T+1]) )

@objective(model2, Min, 0.5 * running_cost + 0.5 * terminal_cost)

# — point initial 
set_start_value.(X[:, 0], x0)
set_start_value.(U, 0.0)

optimize!(model2)
println("Status          : ", termination_status(model2))
println("Objective value : ", objective_value(model2))

# ================================
# Visualisation de la trajectoire et de l’erreur
# ================================

X_val = value.(X)
U_val = value.(U)

J_state4   = 0.0
J_control4 = 0.0

for k in 1:T
    e_k = X_val[:,k] - r[:,k]
    J_state4 += 0.5 * (e_k' * Q * e_k)[1]
end

for k in 0:T-1
    J_control4 += 0.5 * (U_val[:,k]' * R * U_val[:,k])[1]
end

e_final = X_val[:,T] - r[:,T+1]
J_terminal4 = 0.5 * (e_final' * F * e_final)[1]

J4 = J_state4 + J_control4 + J_terminal4

println("\n--- Décomposition du coût : Modèle 4 ---")
println("J_state4    = ", J_state4)
println("J_control4  = ", J_control4)
println("J_terminal4 = ", J_terminal4)
println("J4 total    = ", J4)

solutionX = Array(value.(X))

z = solutionX[11, :]  # position verticale
x = solutionX[7, :]   # position x
y = solutionX[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]
z = solutionX[11, :]  # position verticale
x = solutionX[7, :]   # position x
y = solutionX[9, :]   # position y

# Erreurs de suivi
e_z = z .- r[11, :]
e_x = x .- r[7, :]
e_y = y .- r[9, :]

# Références
r_z = r[11, :]
r_x = r[7, :]
r_y = r[9, :]

t = Ts .* (0:T)  # temps réel en secondes

# Création du layout 3 lignes × 2 colonnes
plt4 = plot(layout = (3, 2), size=(1000, 800))

# Trajectoire x
plot!(plt4[1], t, x, lw=2, label="x (suivie)", color=:blue)
plot!(plt4[1], t, r_x, lw=2, label="x (référence)", linestyle=:dash, color=:red)
plot!(plt4[1], title="Trajectoire en x", xlabel="Temps (s)", ylabel="x (m)", legend=:bottomright, grid=true)

# Erreur x
plot!(plt4[2], t, e_x, lw=2, label="Erreur x", color=:purple)
plot!(plt4[2], title="Erreur de suivi (x)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Trajectoire y
plot!(plt4[3], t, y, lw=2, label="y (suivie)", color=:blue)
plot!(plt4[3], t, r_y, lw=2, label="y (référence)", inestyle=:dash, color=:red)
plot!(plt4[3], title="Trajectoire en y", xlabel="Temps (s)", label="y (m)", legend=:bottomright, grid=true)

# Erreur y
plot!(plt4[4], t, e_y, lw=2, label="Erreur y", color=:purple)
plot!(plt4[4], title="Erreur de suivi (y)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Trajectoire z
plot!(plt4[5], t, z, lw=2, label="z (suivie)", color=:blue)
plot!(plt4[5], t, r_z, lw=2, label="z (référence)", inestyle=:dash, color=:red)
plot!(plt4[5], title="Trajectoire en z", xlabel="Temps (s)", label="z (m)", legend=:bottomright, grid=true)

# Erreur z
plot!(plt4[6], t, e_z, lw=2, label="Erreur z", color=:purple)
plot!(plt4[6], title="Erreur de suivi (z)", xlabel="Temps (s)", label="Erreur (m)", legend=:topright, grid=true)

# Affichage
display(plt4)

```

## Analyse des résultats 

Notons que cette méthode est bien plus efficace que Ipopt et COSMO. La trajectoire désirée est en général mieux approximée, le temps de calcul est meilleur que COSMO en restant très proche de celui d'Ipopt. De plus, la valeur optimale de l'objectif est dix fois plus petite que pour COSMO et cent fois plus petite qu'Ipopt. Cette méthode est donc à privilégier par rapport aux deux méthodes précédentes.


#Description de ce qui à été réalisé

Nous avons reproduit les résultats du papier puis tester différentes méthodes de résolution pour la même trajectoire demandée. 
Cela nous permets de comparer les méthodes sur leurs performances par rapport à la fonction objectif mais aussi par rapport au temps de calcul.

Les résultats sont résumé dans le tableau ci-dessous :   
## Résultats Comparatifs des 4 Modèles

```{julia}
using PrettyTables

modeles = ["Modèle de Riccati", "Ipopt", "Cosmo", "OSQP"]

# Exemples de valeurs (remplace-les)
temps_sec = [0.811, 1.243, 0.400, 0.950]
J_state   = [J_state1, J_state2, J_state3, J_state4]
J_control = [J_control1, J_control2, J_control3, J_control4]
J_terminal= [J_terminal1, J_terminal2, J_terminal3, J_terminal4]
J_total   = J_state .+ J_control .+ J_terminal

data = hcat(
    modeles,
    round.(temps_sec, digits=3),
    round.(J_state, digits=3),
    round.(J_control, digits=3),
    round.(J_terminal, digits=3),
    round.(J_total, digits=3)
)

header = ["Modèle", "Temps (s)", "J_state", "J_control", "J_terminal", "J_total"]

println(pretty_table(String, data; header=header))

```

# Difficultés rencontrées

Pour enrichir le projet, nous avons décidé de faire une recherche pour inclure des algorithmes qui ne sont pas présentés dans le cours. Plusieurs de ces méthodes existent mais ne possèdent pas nécessairement une implémentation simple en Julia ou n’ont pas de documentations claires. Nous avons finalement décidé d’arrêter notre choix sur 2 méthodes: Conic operator splitting method (COSMO) et Operator splitting Quadratic Program (OSQP).

Nous n'arrivons toujours pas à expliquer pourquoi Ipopt ne converge pas dans la troisième dimension (l'axe z). Nous étudions actuellement notre code pour comprendre ce qui génère cette erreur. Comme nous utilisons la même modélisation JUmP pour OSQP et COSMO, nous supposons que cette même erreur rend plus difficile la convergence et c'est pourquoi COSMO ne converge pas en 5000 itérations. Comme son objectif est actuellement meilleurs que celui d'Ipopt, nous avons décidé de le conserver, en espérant pouvoir obtenir de résultats plus satisfaisant lorsque l'erreur de modélisation sera trouvée.

# Description détaillée de ce qui a déjà été accompli :

Pour l’instant, le code a été développé pour recréer les résultats de l’article. Nous avons donc implémenté la méthode récursive de riccati et l’optimisation all at once (cas Ipopt). Nous avons aussi débuté la comparaison avec des méthodes trouvées en ligne mais nous nous frappons à des problèmes de convergences qui seront résolus nous l’espérons d’ici la prochaine phase. Il reste encore à implémenter la résolution de l’optimisation all at once avec un algorithme présenté en cours.

Nous avons complété les consignes de la phase 1 qui étaient manquantes (voir annexe). Cette annexe inclus une description de la problématique, une description des objectifs, une description d'un plan d'action et unedescription de l'impact attendu. Dans la première section de ce rapport, nous avons révisé et présenté la description de la problématique.

Comme nous rencontrons des problèmes de modélisation, nous pouvons difficilement comparer les résultats obtenus des différentes méthodes. Nous avons toutefois résumé les résultats temporaires que nous avons dans un tableau et conservé notre ébauche d'analyse des résultats, que nous avons quelque peu amélioré. Nous ne voulions pas passer trop de temps sur cela tant que l'erreur n'est pas corrigée. Nous estimons que la majorité du code est déjà écris en ce sens que tout devrait bien fonctionné une fois l'erreur de modélisation corrigée. 

# Description détaillée de ce qu'il reste à accomplir. 

## Prioritaire: 
Résoudre l'erreur de modélisation se trouvant dans le code. Une fois l'erreur corrigée, nous pourrons procéder à une analyse plus approfondie de nos résultats. Nous espérons avoir accomplis ceci d'ici une semaine.

## Secondaire : 
Si le temps le permet, nous désirons choisir et implémenter une méthode dédiée aux problèmes quadratiques présentées en cours afin d'enrichir la comparaison des différentes méthodes et de tirer de meilleures conclusions sur la problématique du projet.

## Une semaine avant la remise :
Faire une analyse détaillée des résultats que nous avons obtenus à partir des méthodes que nous auront réussi à implémenter à ce moment là. Les méthodes qui ne seront pas implémentée correctement seront abandonnée.

## 2 jours avant la remise : 
Écrire notre perspectice personnelle sur le projet, dire quels objectifs initiaux ont étés accomplis, compléter la section portant sur la description des difficultés que nous avons rencontrés. Finaliser le rapport, apporter des corrections mineures et faire des retouches.

## Lien Github

[Cliquer ici pour le lien GitHub](https://github.com/joey-van-melle/MTH8408_Optimal-Path-Tracking)


{{< pagebreak >}}

# Annexe (Partie 1)

Nous n'avons pas respecté les consignes demandées dans la partie 1. Voici donc les éléments de cette parties qui ne sont pas nécessairement demandées dans la partie 2 mais que nous
avons jugé utile de rajouter car il s'agit tout de même d'éléments importants à la claireté de notre projet.

# Description de la problématique : 

Le projet consiste à optimiser la trajectoire d’un drone quadrotor à l’aide de méthodes de commande optimale. Les principeaux défis sont : 

- La non-linéarité et l’instabilité naturelle du drone ;
- La consommation énergétique élevée liée à la poussée ;
- Le respect des contraintes physiques sur les angles pour conserver la validité du modèle.

# Description des objectifs : par exemple, quels résultats nous pensons obtenir ou vérifier

Les objectifs du projet sont :

- Modéliser et linéariser la dynamique d’un drone quadrotor ;
- Développer et simuler un algorithme de commande optimale (LQR/Riccati) sur un modèle discret ;
- Vérifier la capacité du contrôleur à :
    * Suivre des trajectoires 3D prédéfinies ;
    * Limiter la consommation énergétique ;
    * Respecter les contraintes sur les angles.

Les résultats attendus sont : 

- Une trajectoire suivie proche de la référence avec des erreurs de suivi faibles ;
- Une commande optimale limitant l’énergie consommée ;
- Des visualisations des trajectoires et erreurs pour valider l’approche.


# Description du plan d’action : où nous allons les informations nécessaires, quelles données vous allez utiliser, etc. ;

Le projet s’articule en plusieurs étapes :

- Modélisation du drone à partir des équations de Newton (translation + rotation) ;
- Simplification et linéarisation autour du vol stationnaire pour obtenir un modèle d’état linéaire ;
- Discrétisation du modèle et définition d’une fonction de coût quadratique (erreurs de suivi + effort de commande) ;
- Résolution du problème d’optimisation avec :
    * Algorithme récursif de Riccati pour l’optimisation sur horizon fini ;
    * Simulation forward pour évaluer le suivi de trajectoire ;
- Visualisation et analyse des résultats (trajectoires suivies, erreurs, consommation) ;
- (Optionnel) : optimisation avec JuMP et Ipopt pour comparer la solution LQR et une résolution all-at-once;
- (Additionnel) : optimisation avec JuMP et des algorithmes qui n'ont pas été présentés dans le cours pour comparer la solution LQR et une résolution all-at-once.
  Ces algortihmes seront trouvés en faisant une recherche sur le web.

# Description de l'impact attendu.

Impact attendu :

- Amélioration de la précision de suivi de trajectoire ;
- Réduction de la consommation d’énergie ;
- Application potentielle à des drones autonomes plus performants pour la logistique, l’observation ou la recherche.

